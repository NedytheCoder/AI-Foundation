{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4efd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#A dataframe is the main data structure in pandas. It is a 2-dimensional labeled data structure with columns of potentially different types.\n",
    "\n",
    "#Sample data. This method works as to populate the row label\n",
    "# data = {\n",
    "#     'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "#     'Age': [24, 27, 22, 32],\n",
    "#     'City': ['New York', 'Los Angeles', 'Chicago', 'Houston']\n",
    "# }\n",
    "data = [['Laptop', 'Smartphone', 'Tablet', 'Monitor'],[1200, 800, 300, 400],[50, 200, 150, 75]]\n",
    "\n",
    "#Creating a DataFrame\n",
    "data = pd.DataFrame(data, columns=['Item1', 'Item2', 'Item3', 'Item4'], index=['Product', 'Price', 'Stock'])\n",
    "print(data)\n",
    "data = [[1,2,3],[4,5,6],[7,8,9]]\n",
    "\n",
    "#Creating a DataFrame\n",
    "data = pd.DataFrame(data, columns=['A', 'B', 'C'], index=['x', 'y', 'z'])\n",
    "\n",
    "#Dataframe operations\n",
    "data.head() #Returns the first n(5 default) rows of the DataFrame\n",
    "data.tail() #Returns the last n rows of the DataFrame\n",
    "data.columns #Returns the column labels of the DataFrame\n",
    "data.index #Returns the row labels of the DataFrame\n",
    "print(\"-------------------\")\n",
    "print(data.describe()) #Generates descriptive statistics of the DataFrame\n",
    "print(\"-------------------\")\n",
    "\n",
    "data.info() #Provides a concise summary of the DataFrame\n",
    "#data.sort_values(by='Item3') #Sorts the DataFrame by the specified column\n",
    "#data['Item1'] #Accessing a specific column\n",
    "#data.loc['Product'] #Accessing a specific row by label\n",
    "data.iloc[1] #Accessing a specific row by integer location\n",
    "data.iloc[0, 2] #Accessing a specific element by row and column indices\n",
    "data.nunique() #Returns the number of unique values in each column\n",
    "data[\"A\"].nunique() #Returns the number of unique values in column A\n",
    "data.unique() #Returns the unique values in column A\n",
    "data[\"A\"].unique() #Returns the number of unique values in column A\n",
    "data.isnull().sum() #Returns the number of missing values in each column\n",
    "data.shape #Returns the dimensions of the DataFrame (rows, columns)\n",
    "data.index.tolist() # Access index values as a list\n",
    "data.size # Number of elements in the DataFrame\n",
    "data.iterrows() # Iterate over DataFrame rows as (index, Series) pairs\n",
    "data.dropna() # Remove rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb16128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>athlete_id</th>\n",
       "      <th>name</th>\n",
       "      <th>born_date</th>\n",
       "      <th>born_city</th>\n",
       "      <th>born_region</th>\n",
       "      <th>born_country</th>\n",
       "      <th>NOC</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>died_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5781</th>\n",
       "      <td>5804</td>\n",
       "      <td>Tommy Burleson</td>\n",
       "      <td>1952-02-24</td>\n",
       "      <td>Crossnore</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>USA</td>\n",
       "      <td>United States</td>\n",
       "      <td>223.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6722</th>\n",
       "      <td>6755</td>\n",
       "      <td>Shaquille O'Neal</td>\n",
       "      <td>1972-03-06</td>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>USA</td>\n",
       "      <td>United States</td>\n",
       "      <td>216.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6937</th>\n",
       "      <td>6972</td>\n",
       "      <td>David Robinson</td>\n",
       "      <td>1965-08-06</td>\n",
       "      <td>Key West</td>\n",
       "      <td>Florida</td>\n",
       "      <td>USA</td>\n",
       "      <td>United States</td>\n",
       "      <td>216.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123850</th>\n",
       "      <td>126093</td>\n",
       "      <td>Tyson Chandler</td>\n",
       "      <td>1982-10-02</td>\n",
       "      <td>Hanford</td>\n",
       "      <td>California</td>\n",
       "      <td>USA</td>\n",
       "      <td>United States</td>\n",
       "      <td>216.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        athlete_id              name   born_date  born_city     born_region  \\\n",
       "5781          5804    Tommy Burleson  1952-02-24  Crossnore  North Carolina   \n",
       "6722          6755  Shaquille O'Neal  1972-03-06     Newark      New Jersey   \n",
       "6937          6972    David Robinson  1965-08-06   Key West         Florida   \n",
       "123850      126093    Tyson Chandler  1982-10-02    Hanford      California   \n",
       "\n",
       "       born_country            NOC  height_cm  weight_kg died_date  \n",
       "5781            USA  United States      223.0      102.0       NaN  \n",
       "6722            USA  United States      216.0      137.0       NaN  \n",
       "6937            USA  United States      216.0      107.0       NaN  \n",
       "123850          USA  United States      216.0      107.0       NaN  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coffee_data = pd.read_csv('csv_files/coffee.csv') # Load data from CSV\n",
    "olympics_data = pd.read_csv('csv_files/bios.csv')\n",
    "\n",
    "coffee_data.sample(5) # Display a random sample of 5 rows. random_state can be set for reproducibility\n",
    "# print(coffee_data.loc[[0,1]])\n",
    "# print(coffee_data[\"Day\"]) # Select a single column\n",
    "# print(coffee_data.loc[[0,1], \"Day\"])\n",
    "# print(\"---------------\")\n",
    "# print(coffee_data.loc[0:3, ['Day', 'Coffee Type']]) # Select specific rows and columns using .loc\n",
    "# print(olympics_data.iloc[0:5, 0:3]) # Select specific rows and columns using .iloc. It's loc but with integer positions\n",
    "# coffee_data.index = coffee_data['Day'] # Set a column as the index\n",
    "# print(coffee_data.head()) # Access index values as a list\n",
    "# print(coffee_data.loc[\"Monday\"]) #Now you can do shit like this with loc\n",
    "# coffee_data.loc[1,\"Units Sold\"] = 100 #Updating the value of a specific cell\n",
    "# #coffee_data.loc[1:4,[\"Day\", \"Units Sold\"]] = 100 #Updating the value of a multiple cells\n",
    "# print(coffee_data.head())\n",
    "\n",
    "# #Accessing Data \n",
    "# coffee_data.sort_values(\"Units Sold\", ascending=False) #For sorting data row-wise with the column\n",
    "\n",
    "# #Filtering Data\n",
    "\n",
    "# olympics_data.loc[olympics_data[\"height_cm\"] > 215].head() # Filter rows based on a condition\n",
    "# olympics_data.loc[olympics_data[\"height_cm\"] > 215, [\"name\", \"height_cm\"]].head() # Filter rows based on a condition\n",
    "# olympics_data[olympics_data[\"height_cm\"] > 215] # Shorter version\n",
    "# olympics_data[olympics_data[\"height_cm\"] > 215][[\"name\", \"height_cm\"]] # Shorter version\n",
    "olympics_data[(olympics_data['height_cm'] > 215) & (olympics_data['born_country'] == 'USA')] # Filter with multiple conditions\n",
    "\n",
    "olympics_data[olympics_data['name'].str.contains('keith', case=False)] # Filter rows where column contains a substring (case-insensitive)\n",
    "olympics_data[olympics_data['name'].str.contains('keith | patrick', case=False)] # Filter rows where column contains a substring (case-insensitive)\n",
    "olympics_data[olympics_data['name'].str.contains(r'^[AEIOUaeiou]', na=False)] # Regex string filter (e.g., names starting with a vowel)\n",
    "olympics_data[olympics_data['born_country'].isin(['USA', 'FRA', 'GBR'])] # Filter rows where column value is in a list\n",
    "\n",
    "olympics_data.query(\"height_cm > 215 and born_country == 'USA'\") # Using query method for filtering with multiple conditions\n",
    "\n",
    "#Adding/Modifying/Removing Columns\n",
    "# coffee = coffee_data.copy() # Create a copy to work with\n",
    "\n",
    "# coffee['price'] = 4.99 # Add a new column with a constant value\n",
    "# coffee['new_price'] = np.where(coffee['Coffee Type'] == 'Espresso', 3.99, 5.99) # Conditional column using numpy.where\n",
    "# coffee.drop(columns=['price'], inplace=True) # Remove column(s) from the DataFrame\n",
    "# coffee.rename(columns={'new_price': 'price'}, inplace=True) # Rename columns\n",
    "# coffee['revenue'] = coffee['Units Sold'] * coffee['price'] # Create new column from existing columns\n",
    "\n",
    "# nocs = pd.read_csv('./data/noc_regions.csv') # Load CSV to use in merge\n",
    "# olympics_data_new = pd.merge(olympics_data, nocs, left_on='born_country', right_on='NOC', how='left') # Merge DataFrames (left join)\n",
    "# usa = olympics_data[olympics_data['born_country'] == 'USA'].copy() # Subset DataFrame\n",
    "# gbr = olympics_data[olympics_data['born_country'] == 'GBR'].copy() # Subset DataFrame\n",
    "# new_df = pd.concat([usa, gbr]) # Concatenate DataFrames\n",
    "\n",
    "# coffee['Units Sold'].fillna(0, inplace=True) # Fill NaNs with a specific value\n",
    "# coffee['Units Sold'].interpolate(inplace=True) # Interpolate missing values\n",
    "# coffee.dropna(subset=['Units Sold'], inplace=True) # Drop rows with NaNs in a subset of columns\n",
    "\n",
    "# olympics_data['born_city'].value_counts() # Value counts for a column\n",
    "# coffee.groupby(['Coffee Type'])['Units Sold'].sum() # Group by and sum aggregation\n",
    "# coffee.groupby(['Coffee Type'])['Units Sold'].mean() # Group by and mean aggregation\n",
    "# pivot = coffee.pivot(columns='Coffee Type', index='Day', values='revenue') # Create a pivot table\n",
    "\n",
    "# coffee['cumsum'] = coffee['Units Sold'].cumsum() # Cumulative sum\n",
    "# latte = coffee[coffee['Coffee Type'] == \"Latte\"].copy() # Subset for a specific coffee type\n",
    "# latte['3day'] = latte['Units Sold'].rolling(3).sum() # 3-day rolling sum\n",
    "# olympics_data['height_rank'] = olympics_data['height_cm'].rank(ascending=False) # Rank values in a column\n",
    "# coffee['yesterday_revenue'] = coffee['revenue'].shift(1) # Shift values down by 1 (lag)\n",
    "\n",
    "# results_arrow = pd.read_csv('./data/results.csv', engine='pyarrow', dtype_backend='pyarrow') # Read CSV using PyArrow backend for performance\n",
    "# results_arrow.info() # Show info for DataFrame loaded with PyArrow backend"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
