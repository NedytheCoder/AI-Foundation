{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4efd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#A dataframe is the main data structure in pandas. It is a 2-dimensional labeled data structure with columns of potentially different types.\n",
    "\n",
    "#Sample data. This method works as to populate the row label\n",
    "# data = {\n",
    "#     'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "#     'Age': [24, 27, 22, 32],\n",
    "#     'City': ['New York', 'Los Angeles', 'Chicago', 'Houston']\n",
    "# }\n",
    "data = [['Laptop', 'Smartphone', 'Tablet', 'Monitor'],[1200, 800, 300, 400],[50, 200, 150, 75]]\n",
    "\n",
    "#Creating a DataFrame\n",
    "data = pd.DataFrame(data, columns=['Item1', 'Item2', 'Item3', 'Item4'], index=['Product', 'Price', 'Stock'])\n",
    "print(data)\n",
    "data = [[1,2,3],[4,5,6],[7,8,9]]\n",
    "\n",
    "#Creating a DataFrame\n",
    "data = pd.DataFrame(data, columns=['A', 'B', 'C'], index=['x', 'y', 'z'])\n",
    "\n",
    "#Dataframe operations\n",
    "data.head() #Returns the first n(5 default) rows of the DataFrame\n",
    "data.tail() #Returns the last n rows of the DataFrame\n",
    "data.columns #Returns the column labels of the DataFrame\n",
    "data.index #Returns the row labels of the DataFrame\n",
    "print(\"-------------------\")\n",
    "print(data.describe()) #Generates descriptive statistics of the DataFrame\n",
    "print(\"-------------------\")\n",
    "\n",
    "data.info() #Provides a concise summary of the DataFrame\n",
    "#data.sort_values(by='Item3') #Sorts the DataFrame by the specified column\n",
    "#data['Item1'] #Accessing a specific column\n",
    "#data.loc['Product'] #Accessing a specific row by label\n",
    "data.iloc[1] #Accessing a specific row by integer location\n",
    "data.iloc[0, 2] #Accessing a specific element by row and column indices\n",
    "data.nunique() #Returns the number of unique values in each column\n",
    "data[\"A\"].nunique() #Returns the number of unique values in column A\n",
    "data.unique() #Returns the unique values in column A\n",
    "data[\"A\"].unique() #Returns the number of unique values in column A\n",
    "data.isnull().sum() #Returns the number of missing values in each column\n",
    "data.shape #Returns the dimensions of the DataFrame (rows, columns)\n",
    "data.index.tolist() # Access index values as a list\n",
    "data.size # Number of elements in the DataFrame\n",
    "data.iterrows() # Iterate over DataFrame rows as (index, Series) pairs\n",
    "data.dropna() # Remove rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb16128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "coffee_data = pd.read_csv('csv_files/coffee.csv') # Load data from CSV\n",
    "olympics_data = pd.read_csv('csv_files/bios.csv')\n",
    "\n",
    "coffee_data.sample(5) # Display a random sample of 5 rows. random_state can be set for reproducibility\n",
    "print(coffee_data.loc[[0,1]])\n",
    "print(coffee_data[\"Day\"]) # Select a single column\n",
    "print(coffee_data.loc[[0,1], \"Day\"])\n",
    "print(\"---------------\")\n",
    "print(coffee_data.loc[0:3, ['Day', 'Coffee Type']]) # Select specific rows and columns using .loc\n",
    "print(olympics_data.iloc[0:5, 0:3]) # Select specific rows and columns using .iloc. It's loc but with integer positions\n",
    "coffee_data.index = coffee_data['Day'] # Set a column as the index\n",
    "print(coffee_data.head()) # Access index values as a list\n",
    "print(coffee_data.loc[\"Monday\"]) #Now you can do shit like this with loc\n",
    "coffee_data.loc[1,\"Units Sold\"] = 100 #Updating the value of a specific cell\n",
    "#coffee_data.loc[1:4,[\"Day\", \"Units Sold\"]] = 100 #Updating the value of a multiple cells\n",
    "print(coffee_data.head())\n",
    "\n",
    "#Accessing Data \n",
    "coffee_data.sort_values(\"Units Sold\", ascending=False) #For sorting data row-wise with the column\n",
    "\n",
    "#Filtering Data\n",
    "\n",
    "olympics_data.loc[olympics_data[\"height_cm\"] > 215].head() # Filter rows based on a condition\n",
    "olympics_data.loc[olympics_data[\"height_cm\"] > 215, [\"name\", \"height_cm\"]].head() # Filter rows based on a condition\n",
    "olympics_data[olympics_data[\"height_cm\"] > 215] # Shorter version\n",
    "olympics_data[olympics_data[\"height_cm\"] > 215][[\"name\", \"height_cm\"]] # Shorter version\n",
    "olympics_data[(olympics_data['height_cm'] > 215) & (olympics_data['born_country'] == 'USA')] # Filter with multiple conditions\n",
    "\n",
    "olympics_data[olympics_data['name'].str.contains('keith', case=False)] # Filter rows where column contains a substring (case-insensitive)\n",
    "olympics_data[olympics_data['name'].str.contains('keith | patrick', case=False)] # Filter rows where column contains a substring (case-insensitive)\n",
    "olympics_data[olympics_data['name'].str.contains(r'^[AEIOUaeiou]', na=False)] # Regex string filter (e.g., names starting with a vowel)\n",
    "olympics_data[olympics_data['born_country'].isin(['USA', 'FRA', 'GBR'])] # Filter rows where column value is in a list\n",
    "\n",
    "olympics_data.query(\"height_cm > 215 and born_country == 'USA'\") # Using query method for filtering with multiple conditions\n",
    "\n",
    "#Adding/Modifying/Removing Columns\n",
    "\n",
    "coffee_copy = coffee_data.copy() # Create a copy to work with\n",
    "\n",
    "coffee_copy['price'] = 4.99 # Add a new column with a constant value\n",
    "coffee_copy.head()\n",
    "coffee_copy['new_price'] = np.where(coffee_copy['Coffee Type'] == 'Espresso', 3.99, 5.99) # Conditional column using numpy.where. Basically adding a new column based on a condition\n",
    "coffee_copy.drop(0, axis=0, inplace=True) # Remove row(s) from the DataFrame\n",
    "coffee_copy.drop(columns=['price'], inplace=True) # Remove column(s) from the DataFrame\n",
    "coffee_copy[\"revenue\"] = coffee_copy['Units Sold'] * coffee_copy['new_price'] # Create new column from existing columns\n",
    "coffee_copy.rename(columns={'new_price': 'price'}, inplace=True) # Rename columns\n",
    "coffee_copy.head()\n",
    "\n",
    "olympics_copy = olympics_data.copy() # Create a copy to work with\n",
    "olympics_copy[\"firstname\"] = olympics_copy['name'].str.split(' ').str[0] # Extract first name from full name\\\n",
    "olympics_copy[\"born_datetime\"] = pd.to_datetime(olympics_copy['born_date']) # Convert string to datetime\n",
    "olympics_copy[\"born_year\"] = olympics_copy['born_datetime'].dt.year # Extract year from datetime\n",
    "#olympics_copy[\"age_at_first_olympics\"] = olympics_copy['first_olympic_year'] - olympics_copy['born_year'] # Calculate age at first Olympics\n",
    "olympics_copy[\"height_category\"] = olympics_copy['height_cm'].apply(lambda x: 'Tall' if x > 190 else 'Average' if x >= 170 else 'Short') # Categorize height using apply with a lambda function\n",
    "def weight_category(weight): # Function to categorize weight. Although using a lambda is more concise\n",
    "    if weight < 70:\n",
    "        return 'Light'\n",
    "    elif 70 <= weight <= 90:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'Heavy'\n",
    "#olympics_copy[\"weight_category\"] = olympics_copy.apply(weight_category, axis=1) # Categorize weight using apply with a function\n",
    "olympics_copy[\"weight_category\"] = olympics_copy['weight_kg'].apply(weight_category) # Categorize weight using apply with a function\n",
    "olympics_copy.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effe80ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging/Concatenating DataFrames\n",
    "nocs = pd.read_csv('csv_files/noc_regions.csv') # Load CSV to use in merge\n",
    "nocs.head() \n",
    "olympics_data_new = pd.merge(olympics_data, nocs, left_on='born_country', right_on='NOC', how='left', suffixes=('', '_right')) # Merge DataFrames (left join)\n",
    "olympics_copy.head()\n",
    "olympics_data_new.rename(columns={'region': 'born_country_full'}, inplace=True)\n",
    "olympics_data_new.head()\n",
    "usa = olympics_data[olympics_data['born_country'] == 'USA'].copy() # Subset DataFrame\n",
    "gbr = olympics_data[olympics_data['born_country'] == 'GBR'].copy() # Subset DataFrame\n",
    "new_df = pd.concat([usa, gbr]) # Concatenate DataFrames, one over the other\n",
    "\n",
    "#Handling Missing Data/nulls\n",
    "coffee_copy = coffee_data.copy() # Create a copy to work with\n",
    "coffee_copy.loc[1:3, \"Units Sold\"] = np.nan # Introduce NaN values for demonstration\n",
    "coffee_copy.fillna(coffee_copy['Units Sold'].mean(), inplace=True) # Fill NaNs with the mean of the column\n",
    "coffee_copy['Units Sold'].fillna(100, inplace=True) # Fill NaNs with a specific value\n",
    "#coffee.isnull().sum() # Count missing values in each column\n",
    "coffee_copy['Units Sold'].interpolate(inplace=True) # Interpolate missing values when the nans are in between non-nan values\n",
    "print(coffee_copy.head())\n",
    "coffee_copy[coffee_copy['Units Sold'].notna()] # Drop rows with NaNs in a subset of columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a70e999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Coffee Type</th>\n",
       "      <th>Units Sold</th>\n",
       "      <th>price</th>\n",
       "      <th>revenue</th>\n",
       "      <th>yesterday_revenue</th>\n",
       "      <th>pct_change</th>\n",
       "      <th>3days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Latte</td>\n",
       "      <td>15</td>\n",
       "      <td>5.99</td>\n",
       "      <td>89.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Latte</td>\n",
       "      <td>20</td>\n",
       "      <td>5.99</td>\n",
       "      <td>119.80</td>\n",
       "      <td>89.85</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Latte</td>\n",
       "      <td>25</td>\n",
       "      <td>5.99</td>\n",
       "      <td>149.75</td>\n",
       "      <td>119.80</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>Latte</td>\n",
       "      <td>30</td>\n",
       "      <td>5.99</td>\n",
       "      <td>179.70</td>\n",
       "      <td>149.75</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Friday</td>\n",
       "      <td>Latte</td>\n",
       "      <td>35</td>\n",
       "      <td>5.99</td>\n",
       "      <td>209.65</td>\n",
       "      <td>179.70</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>Latte</td>\n",
       "      <td>35</td>\n",
       "      <td>5.99</td>\n",
       "      <td>209.65</td>\n",
       "      <td>209.65</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>Latte</td>\n",
       "      <td>35</td>\n",
       "      <td>5.99</td>\n",
       "      <td>209.65</td>\n",
       "      <td>209.65</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Day Coffee Type  Units Sold  price  revenue  yesterday_revenue  \\\n",
       "1      Monday       Latte          15   5.99    89.85                NaN   \n",
       "3     Tuesday       Latte          20   5.99   119.80              89.85   \n",
       "5   Wednesday       Latte          25   5.99   149.75             119.80   \n",
       "7    Thursday       Latte          30   5.99   179.70             149.75   \n",
       "9      Friday       Latte          35   5.99   209.65             179.70   \n",
       "11   Saturday       Latte          35   5.99   209.65             209.65   \n",
       "13     Sunday       Latte          35   5.99   209.65             209.65   \n",
       "\n",
       "    pct_change  3days  \n",
       "1          NaN    NaN  \n",
       "3   133.333333    NaN  \n",
       "5   125.000000   60.0  \n",
       "7   120.000000   75.0  \n",
       "9   116.666667   90.0  \n",
       "11  100.000000  100.0  \n",
       "13  100.000000  105.0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aggregation/GroupBy/Pivot Tables/Window Functions with data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "coffee = pd.read_csv(\"csv_files/coffee.csv\")\n",
    "coffee['price'] = np.where(coffee['Coffee Type'] == 'Espresso', 3.99, 5.99)\n",
    "coffee[\"revenue\"] = coffee['Units Sold'] * coffee['price']\n",
    "coffee.groupby(['Coffee Type'])[\"Units Sold\"].sum() # Group by and sum aggregation\n",
    "coffee.groupby(['Coffee Type', 'Day'])[\"Units Sold\"].sum() # Multiple group bys and sum aggregation\n",
    "coffee.groupby(['Coffee Type']).agg({\"Units Sold\": \"sum\", \"price\": \"mean\"}) # Group by and multiple operation aggregation\n",
    "pivot = coffee.pivot(columns=\"Coffee Type\", index=\"Day\", values=\"revenue\")#You can now proceed to find info easily with the mentioned csv file operations earlier\n",
    "coffee\n",
    "pivot\n",
    "\n",
    "olympics = pd.read_csv('csv_files/bios.csv')\n",
    "olympics[\"born_datetime\"] = pd.to_datetime(olympics['born_date'])\n",
    "olympics[\"born_year\"] = olympics['born_datetime'].dt.year\n",
    "olympics.groupby([olympics[\"born_year\"], olympics['born_datetime'].dt.month])[\"name\"].count().reset_index().sort_values(\"name\", ascending=False) #Count is for counting the values in the generator object created by the groupby method, and reset_index is the convert the messy data into a simple easy-to-read table.\n",
    "\n",
    "#Advanced functionalities like shift, rank and cumsum\n",
    "coffee['yesterday_revenue'] = coffee['revenue'].shift(2) # Shift values down by 1 (lag)\n",
    "coffee['pct_change'] = coffee['revenue'] / coffee['yesterday_revenue'] * 100\n",
    "olympics['height_rank'] = olympics['height_cm'].rank(ascending=False) # Rank values in a column\n",
    "olympics.sort_values(['height_rank'])\n",
    "# coffee['cumsum'] = coffee['revenue'].cumsum() # Cumulative sum\n",
    "latte = coffee[coffee['Coffee Type'] == \"Latte\"].copy()\n",
    "latte['3days'] = latte['Units Sold'].rolling(3).sum()\n",
    "latte\n",
    "results_arrow = pd.read_csv('./data/results.csv', engine='pyarrow', dtype_backend='pyarrow') # Read CSV using PyArrow backend for performance\n",
    "results_arrow.info() # Show info for DataFrame loaded with PyArrow backend"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
